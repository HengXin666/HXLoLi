# 并行、指令和同步
> 简而言之: 会在「操作系统」里面细致讲解!

当任务之间相互独立的时候，任务的并行执行是比较容易的。而大多数时候，往往是很多任务要协作进行，共享资源进行读取操作。当多个任务共享资源并进行读写操作时，必须确保它们之间以一种有序且安全的方式进行协作，防止数据不一致和错误结果。

> 数据竞争（Data Race）是指在多线程或多进程环境下，当两个或多个任务同时访问和修改同一内存位置，并且至少有一个是写操作时，如果没有采取任何同步措施来控制访问顺序，则可能导致不可预测的结果。
>
> 假设我们有两个线程（或任务），线程A和线程B，它们都需要访问和修改一个共享的整数变量 x 。
> ```C++
> int x = 0; // 共享变量，初始化为0
> 
> // 线程A的代码
> void threadA() {
>     x = 1; // 线程A将x设置为1
> }
> 
> // 线程B的代码
> void thread() {
>     int y = x; // 线程B读取x的值到y中
>     if (y == 0)
>         printf("x 是 0\n");
>     else
>         printf("x 非 0\n");
> }
> ```
> 现在，假设这两个线程几乎同时运行。线程A可能刚刚将 x 设置为1，而线程B正在读取 x 的值。没有同步机制的情况下，线程B可能会读取到一个中间状态或旧的 x 的值（比如0），即使线程A已经修改了它。


为了确保数据的一致性和正确性，防止数**据竞争和条件竞争(race conditions)** 的发生，我们发明了同步机制。

同步机制是确保在多线程或多处理器环境中正确协调共享资源访问的关键技术。这些同步机制依赖于硬件提供的同步指令，这些指令允许软件开发者在编程时创建互斥区域，确保在任何时候只有一个线程或处理器能够访问特定的代码段或数据。

加锁（lock）和解锁（unlock）是同步机制中最基础的操作。

硬件提供的同步指令是实现加锁和解锁操作的基础。

除了简单的加锁和解锁操作外，更复杂的同步机制如条件变量、信号量、读写锁（操作系统中会详细见到这些东西）等也是基于类似的原理实现的。这些机制提供了更细粒度的控制和更灵活的同步方式，以适应不同的并发场景和需求。

虽然同步机制可以有效地协调共享资源的访问，但它们也可能引入性能开销和死锁等问题。因此，在使用同步机制时，需要仔细考虑其适用场景和潜在风险，并采取适当的措施来避免或解决这些问题。